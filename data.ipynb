{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>meal type</th>\n",
       "      <th>person type</th>\n",
       "      <th>diet type</th>\n",
       "      <th>recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>veg</td>\n",
       "      <td>breakfast</td>\n",
       "      <td>atheletic</td>\n",
       "      <td>high protein</td>\n",
       "      <td>panner salad with some brown bread,add some oa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non veg</td>\n",
       "      <td>breakfast</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>idly or dosa or any type of breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>veg</td>\n",
       "      <td>breakfast</td>\n",
       "      <td>weight loss</td>\n",
       "      <td>low carb</td>\n",
       "      <td>fruits and panner,sugar free foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non veg</td>\n",
       "      <td>breakfast</td>\n",
       "      <td>weight gain</td>\n",
       "      <td>high protein</td>\n",
       "      <td>eggs and chicken salad and some beetroot juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non veg</td>\n",
       "      <td>lunch</td>\n",
       "      <td>atheletic</td>\n",
       "      <td>high protein</td>\n",
       "      <td>chicken breast and some vegetables like capsic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type   meal type  person type     diet type  \\\n",
       "0      veg   breakfast    atheletic  high protein   \n",
       "1  non veg   breakfast       normal        normal   \n",
       "2      veg   breakfast  weight loss      low carb   \n",
       "3  non veg  breakfast   weight gain  high protein   \n",
       "4  non veg       lunch    atheletic  high protein   \n",
       "\n",
       "                                           recommend  \n",
       "0  panner salad with some brown bread,add some oa...  \n",
       "1              idly or dosa or any type of breakfast  \n",
       "2                 fruits and panner,sugar free foods  \n",
       "3     eggs and chicken salad and some beetroot juice  \n",
       "4  chicken breast and some vegetables like capsic...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(r\"C:\\Users\\VIKRAM\\Downloads\\NLP DATASET.xlsx\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type           0\n",
       "meal type      0\n",
       "person type    0\n",
       "diet type      0\n",
       "recommend      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_string(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type',\n",
       " 'meal',\n",
       " 'type',\n",
       " 'person',\n",
       " 'type',\n",
       " 'diet',\n",
       " 'type',\n",
       " 'recommend',\n",
       " 'veg',\n",
       " 'breakfast',\n",
       " 'atheletic',\n",
       " 'high',\n",
       " 'protein',\n",
       " 'panner',\n",
       " 'salad',\n",
       " 'with',\n",
       " 'some',\n",
       " 'brown',\n",
       " 'bread',\n",
       " ',',\n",
       " 'add',\n",
       " 'some',\n",
       " 'oats',\n",
       " 'with',\n",
       " 'milk',\n",
       " 'and',\n",
       " 'whey',\n",
       " 'protein',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'breakfast',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'idly',\n",
       " 'or',\n",
       " 'dosa',\n",
       " 'or',\n",
       " 'any',\n",
       " 'type',\n",
       " 'of',\n",
       " 'breakfast',\n",
       " 'veg',\n",
       " 'breakfast',\n",
       " 'weight',\n",
       " 'loss',\n",
       " 'low',\n",
       " 'carb',\n",
       " 'fruits',\n",
       " 'and',\n",
       " 'panner',\n",
       " ',',\n",
       " 'sugar',\n",
       " 'free',\n",
       " 'foods',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'breakfast',\n",
       " 'weight',\n",
       " 'gain',\n",
       " 'high',\n",
       " 'protein',\n",
       " 'eggs',\n",
       " 'and',\n",
       " 'chicken',\n",
       " 'salad',\n",
       " 'and',\n",
       " 'some',\n",
       " 'beetroot',\n",
       " 'juice',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'lunch',\n",
       " 'atheletic',\n",
       " 'high',\n",
       " 'protein',\n",
       " 'chicken',\n",
       " 'breast',\n",
       " 'and',\n",
       " 'some',\n",
       " 'vegetables',\n",
       " 'like',\n",
       " 'capsicum',\n",
       " 'and',\n",
       " 'yogurt',\n",
       " 'or',\n",
       " 'curd',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'lunch',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'chicken',\n",
       " 'curry',\n",
       " 'or',\n",
       " 'fry',\n",
       " 'and',\n",
       " 'rice',\n",
       " 'and',\n",
       " 'add',\n",
       " 'some',\n",
       " 'veggies',\n",
       " 'if',\n",
       " 'you',\n",
       " 'want',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'lunch',\n",
       " 'weight',\n",
       " 'loss',\n",
       " 'low',\n",
       " 'carb',\n",
       " 'chicken',\n",
       " 'breast',\n",
       " 'and',\n",
       " 'rice',\n",
       " 'and',\n",
       " 'add',\n",
       " 'some',\n",
       " 'scrambled',\n",
       " 'eggs',\n",
       " 'and',\n",
       " 'take',\n",
       " 'some',\n",
       " 'yougurt',\n",
       " 'if',\n",
       " 'you',\n",
       " 'want',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'lunch',\n",
       " 'weight',\n",
       " 'gain',\n",
       " 'high',\n",
       " 'carb',\n",
       " 'chicken',\n",
       " 'breast',\n",
       " 'and',\n",
       " 'some',\n",
       " 'vegetables',\n",
       " 'like',\n",
       " 'capsicum',\n",
       " 'and',\n",
       " 'yogurt',\n",
       " 'or',\n",
       " 'curd',\n",
       " 'veg',\n",
       " 'dinner',\n",
       " 'atheletic',\n",
       " 'high',\n",
       " 'protein',\n",
       " 'chapathi',\n",
       " 'kurma',\n",
       " 'milk',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'dinner',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'idly',\n",
       " ',',\n",
       " 'rice',\n",
       " ',',\n",
       " 'curry',\n",
       " 'and',\n",
       " 'milk',\n",
       " 'veg',\n",
       " 'dinner',\n",
       " 'weight',\n",
       " 'loss',\n",
       " 'low',\n",
       " 'carb',\n",
       " 'eggs',\n",
       " ',',\n",
       " 'chicken',\n",
       " 'breast',\n",
       " 'and',\n",
       " 'tuna',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'dinner',\n",
       " 'weight',\n",
       " 'gain',\n",
       " 'high',\n",
       " 'protein',\n",
       " 'chicken',\n",
       " 'breast',\n",
       " ',',\n",
       " 'salmon',\n",
       " ',',\n",
       " 'one',\n",
       " 'egg',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'breakfast',\n",
       " 'atheletic',\n",
       " 'high',\n",
       " 'protein',\n",
       " 'fruits',\n",
       " 'and',\n",
       " 'panner',\n",
       " ',',\n",
       " 'sugar',\n",
       " 'free',\n",
       " 'foods',\n",
       " 'veg',\n",
       " 'breakfast',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'idly',\n",
       " 'or',\n",
       " 'dosa',\n",
       " 'or',\n",
       " 'any',\n",
       " 'type',\n",
       " 'of',\n",
       " 'breakfast',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'breakfast',\n",
       " 'weight',\n",
       " 'loss',\n",
       " 'low',\n",
       " 'carb',\n",
       " 'eggs',\n",
       " 'and',\n",
       " 'chicken',\n",
       " 'salad',\n",
       " 'and',\n",
       " 'some',\n",
       " 'beetroot',\n",
       " 'juice',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'lunch',\n",
       " 'weight',\n",
       " 'gain',\n",
       " 'high',\n",
       " 'protein',\n",
       " 'chicken',\n",
       " 'curry',\n",
       " 'or',\n",
       " 'fry',\n",
       " 'and',\n",
       " 'rice',\n",
       " 'and',\n",
       " 'add',\n",
       " 'some',\n",
       " 'veggies',\n",
       " 'if',\n",
       " 'you',\n",
       " 'want',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'lunch',\n",
       " 'atheletic',\n",
       " 'high',\n",
       " 'protein',\n",
       " 'chicken',\n",
       " 'breast',\n",
       " 'and',\n",
       " 'some',\n",
       " 'vegetables',\n",
       " 'like',\n",
       " 'capsicum',\n",
       " 'and',\n",
       " 'yogurt',\n",
       " 'or',\n",
       " 'curd',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'lunch',\n",
       " 'normal',\n",
       " 'normal',\n",
       " 'chicken',\n",
       " 'curry',\n",
       " 'or',\n",
       " 'fry',\n",
       " 'and',\n",
       " 'rice',\n",
       " 'and',\n",
       " 'add',\n",
       " 'some',\n",
       " 'veggies',\n",
       " 'if',\n",
       " 'you',\n",
       " 'want',\n",
       " 'veg',\n",
       " 'dinner',\n",
       " 'weight',\n",
       " 'loss',\n",
       " 'low',\n",
       " 'carb',\n",
       " 'chapathi',\n",
       " 'kurma',\n",
       " 'milk',\n",
       " 'non',\n",
       " 'veg',\n",
       " 'dinner',\n",
       " 'weight',\n",
       " 'gain',\n",
       " 'high',\n",
       " 'protein',\n",
       " 'chicken',\n",
       " 'breast',\n",
       " ',',\n",
       " 'salmon',\n",
       " ',',\n",
       " 'one',\n",
       " 'egg']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "token = word_tokenize(data)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type', 'meal', 'type', 'person', 'type', 'diet', 'type', 'recommend', 'veg', 'breakfast', 'atheletic', 'high', 'protein', 'panner', 'salad', 'with', 'some', 'brown', 'bread', ',', 'add', 'some', 'oats', 'with', 'milk', 'and', 'whey', 'protein', 'non', 'veg', 'breakfast', 'normal', 'normal', 'idly', 'or', 'dosa', 'or', 'any', 'type', 'of', 'breakfast', 'veg', 'breakfast', 'weight', 'loss', 'low', 'carb', 'fruits', 'and', 'panner', ',', 'sugar', 'free', 'foods', 'non', 'veg', 'breakfast', 'weight', 'gain', 'high', 'protein', 'eggs', 'and', 'chicken', 'salad', 'and', 'some', 'beetroot', 'juice', 'non', 'veg', 'lunch', 'atheletic', 'high', 'protein', 'chicken', 'breast', 'and', 'some', 'vegetables', 'like', 'capsicum', 'and', 'yogurt', 'or', 'curd', 'non', 'veg', 'lunch', 'normal', 'normal', 'chicken', 'curry', 'or', 'fry', 'and', 'rice', 'and', 'add', 'some', 'veggies', 'if', 'you', 'want', 'non', 'veg', 'lunch', 'weight', 'loss', 'low', 'carb', 'chicken', 'breast', 'and', 'rice', 'and', 'add', 'some', 'scrambled', 'eggs', 'and', 'take', 'some', 'yougurt', 'if', 'you', 'want', 'non', 'veg', 'lunch', 'weight', 'gain', 'high', 'carb', 'chicken', 'breast', 'and', 'some', 'vegetables', 'like', 'capsicum', 'and', 'yogurt', 'or', 'curd', 'veg', 'dinner', 'atheletic', 'high', 'protein', 'chapathi', 'kurma', 'milk', 'non', 'veg', 'dinner', 'normal', 'normal', 'idly', ',', 'rice', ',', 'curry', 'and', 'milk', 'veg', 'dinner', 'weight', 'loss', 'low', 'carb', 'eggs', ',', 'chicken', 'breast', 'and', 'tuna', 'non', 'veg', 'dinner', 'weight', 'gain', 'high', 'protein', 'chicken', 'breast', ',', 'salmon', ',', 'one', 'egg', 'non', 'veg', 'breakfast', 'atheletic', 'high', 'protein', 'fruits', 'and', 'panner', ',', 'sugar', 'free', 'foods', 'veg', 'breakfast', 'normal', 'normal', 'idly', 'or', 'dosa', 'or', 'any', 'type', 'of', 'breakfast', 'non', 'veg', 'breakfast', 'weight', 'loss', 'low', 'carb', 'eggs', 'and', 'chicken', 'salad', 'and', 'some', 'beetroot', 'juice', 'non', 'veg', 'lunch', 'weight', 'gain', 'high', 'protein', 'chicken', 'curry', 'or', 'fry', 'and', 'rice', 'and', 'add', 'some', 'veggies', 'if', 'you', 'want', 'non', 'veg', 'lunch', 'atheletic', 'high', 'protein', 'chicken', 'breast', 'and', 'some', 'vegetables', 'like', 'capsicum', 'and', 'yogurt', 'or', 'curd', 'non', 'veg', 'lunch', 'normal', 'normal', 'chicken', 'curry', 'or', 'fry', 'and', 'rice', 'and', 'add', 'some', 'veggies', 'if', 'you', 'want', 'veg', 'dinner', 'weight', 'loss', 'low', 'carb', 'chapathi', 'kurma', 'milk', 'non', 'veg', 'dinner', 'weight', 'gain', 'high', 'protein', 'chicken', 'breast', ',', 'salmon', ',', 'one', 'egg']\n",
      "['type', 'meal', 'type', 'person', 'type', 'diet', 'type', 'recommend', 'veg', 'breakfast', 'atheletic', 'high', 'protein', 'panner', 'salad', 'brown', 'bread', ',', 'add', 'oats', 'milk', 'whey', 'protein', 'non', 'veg', 'breakfast', 'normal', 'normal', 'idly', 'dosa', 'type', 'breakfast', 'veg', 'breakfast', 'weight', 'loss', 'low', 'carb', 'fruits', 'panner', ',', 'sugar', 'free', 'foods', 'non', 'veg', 'breakfast', 'weight', 'gain', 'high', 'protein', 'eggs', 'chicken', 'salad', 'beetroot', 'juice', 'non', 'veg', 'lunch', 'atheletic', 'high', 'protein', 'chicken', 'breast', 'vegetables', 'like', 'capsicum', 'yogurt', 'curd', 'non', 'veg', 'lunch', 'normal', 'normal', 'chicken', 'curry', 'fry', 'rice', 'add', 'veggies', 'want', 'non', 'veg', 'lunch', 'weight', 'loss', 'low', 'carb', 'chicken', 'breast', 'rice', 'add', 'scrambled', 'eggs', 'take', 'yougurt', 'want', 'non', 'veg', 'lunch', 'weight', 'gain', 'high', 'carb', 'chicken', 'breast', 'vegetables', 'like', 'capsicum', 'yogurt', 'curd', 'veg', 'dinner', 'atheletic', 'high', 'protein', 'chapathi', 'kurma', 'milk', 'non', 'veg', 'dinner', 'normal', 'normal', 'idly', ',', 'rice', ',', 'curry', 'milk', 'veg', 'dinner', 'weight', 'loss', 'low', 'carb', 'eggs', ',', 'chicken', 'breast', 'tuna', 'non', 'veg', 'dinner', 'weight', 'gain', 'high', 'protein', 'chicken', 'breast', ',', 'salmon', ',', 'one', 'egg', 'non', 'veg', 'breakfast', 'atheletic', 'high', 'protein', 'fruits', 'panner', ',', 'sugar', 'free', 'foods', 'veg', 'breakfast', 'normal', 'normal', 'idly', 'dosa', 'type', 'breakfast', 'non', 'veg', 'breakfast', 'weight', 'loss', 'low', 'carb', 'eggs', 'chicken', 'salad', 'beetroot', 'juice', 'non', 'veg', 'lunch', 'weight', 'gain', 'high', 'protein', 'chicken', 'curry', 'fry', 'rice', 'add', 'veggies', 'want', 'non', 'veg', 'lunch', 'atheletic', 'high', 'protein', 'chicken', 'breast', 'vegetables', 'like', 'capsicum', 'yogurt', 'curd', 'non', 'veg', 'lunch', 'normal', 'normal', 'chicken', 'curry', 'fry', 'rice', 'add', 'veggies', 'want', 'veg', 'dinner', 'weight', 'loss', 'low', 'carb', 'chapathi', 'kurma', 'milk', 'non', 'veg', 'dinner', 'weight', 'gain', 'high', 'protein', 'chicken', 'breast', ',', 'salmon', ',', 'one', 'egg']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokens = word_tokenize(data)\n",
    "# converts the words in word_tokens to lower case and then checks whether \n",
    "#they are present in stop_words or not\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "#with no lower case conversion\n",
    "filtered_sentence = []\n",
    " \n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    " \n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   type  meal type person type    diet type                                                                             recommend\\n    veg  breakfast   atheletic high protein           panner salad with some brown bread,add some oats with milk and whey protein\\nnon veg  breakfast      normal       normal                                                 idly or dosa or any type of breakfast\\n    veg  breakfast weight loss     low carb                                                    fruits and panner,sugar free foods\\nnon veg breakfast  weight gain high protein                                        eggs and chicken salad and some beetroot juice\\nnon veg      lunch   atheletic high protein                   chicken breast and some vegetables like capsicum and yogurt or curd\\nnon veg      lunch      normal       normal                        chicken curry or fry and rice and add some veggies if you want\\nnon veg      lunch weight loss     low carb chicken breast and rice and add some scrambled eggs and take some yougurt if you want\\nnon veg      lunch weight gain    high carb                   chicken breast and some vegetables like capsicum and yogurt or curd\\n    veg     dinner   atheletic high protein                                                                   chapathi kurma milk\\nnon veg     dinner      normal       normal                                                             idly,rice, curry and milk\\n    veg     dinner weight loss     low carb                                                          eggs,chicken breast and tuna\\nnon veg     dinner weight gain high protein                                                         chicken breast,salmon,one egg\\nnon veg  breakfast   atheletic high protein                                                    fruits and panner,sugar free foods\\n    veg  breakfast      normal       normal                                                 idly or dosa or any type of breakfast\\nnon veg  breakfast weight loss     low carb                                        eggs and chicken salad and some beetroot juice\\nnon veg      lunch weight gain high protein                        chicken curry or fry and rice and add some veggies if you want\\nnon veg      lunch   atheletic high protein                   chicken breast and some vegetables like capsicum and yogurt or curd\\nnon veg      lunch      normal       normal                        chicken curry or fry and rice and add some veggies if you want\\n    veg     dinner weight loss     low carb                                                                   chapathi kurma milk\\nnon veg     dinner weight gain high protein                                                         chicken breast,salmon,one egg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# import these modules\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "a=lemmatizer.lemmatize(data)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeal type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mperson type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdiet type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m y\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecomend\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'list'"
     ]
    }
   ],
   "source": [
    "x=data[[\"type\",\"meal type\",\"person type\",\"diet type\"]]\n",
    "y=data['recomend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended food: panner salad with some brown bread,add some oats with milk and whey protein\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Ensure you download stopwords and punkt before use\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(r\"C:\\Users\\VIKRAM\\Downloads\\NLP DATASET.xlsx\")\n",
    "\n",
    "# Step 1: Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers and special characters\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Join the cleaned words back into a single string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Step 2: Apply preprocessing to each of the columns that we'll use\n",
    "df['type'] = df['type'].apply(preprocess_text)\n",
    "df['meal type'] = df['meal type'].apply(preprocess_text)\n",
    "df['person type'] = df['person type'].apply(preprocess_text)\n",
    "df['diet type'] = df['diet type'].apply(preprocess_text)\n",
    "\n",
    "# Combine the relevant columns to create a feature set for the recommendation system\n",
    "df['features'] = df['type'] + \" \" + df['meal type'] + \" \" + df['person type'] + \" \" + df['diet type']\n",
    "\n",
    "# Step 3: Initialize TF-IDF Vectorizer for feature extraction\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data into TF-IDF vectors\n",
    "tfidf_matrix = vectorizer.fit_transform(df['features'])\n",
    "\n",
    "# Step 4: Define the recommendation function\n",
    "def recommend_food_nlp(meal_type, food_type, person_type, diet_type):\n",
    "    # Preprocess the user input\n",
    "    food_type = preprocess_text(food_type)\n",
    "    meal_type = preprocess_text(meal_type)\n",
    "    person_type = preprocess_text(person_type)\n",
    "    diet_type = preprocess_text(diet_type)\n",
    "    \n",
    "    # Combine the inputs into a query\n",
    "    user_input = f\"{food_type} {meal_type} {person_type} {diet_type}\"\n",
    "    \n",
    "    # Transform the user input into the TF-IDF vector\n",
    "    user_tfidf = vectorizer.transform([user_input])\n",
    "    \n",
    "    # Calculate the cosine similarity between user input and dataset\n",
    "    similarities = cosine_similarity(user_tfidf, tfidf_matrix)\n",
    "    \n",
    "    # Get the index of the highest similarity score\n",
    "    idx = similarities.argsort()[0][-1]\n",
    "    \n",
    "    # Return the recommended food\n",
    "    return df['recommend'].iloc[idx]\n",
    "\n",
    "# Step 5: Example usage with test inputs\n",
    "meal_type = \"breakfast\"\n",
    "food_type = \"veg\"\n",
    "person_type = \"atheletic\"\n",
    "diet_type = \"high protein\"\n",
    "\n",
    "recommendation = recommend_food_nlp(meal_type, food_type, person_type, diet_type)\n",
    "print(\"Recommended food:\", recommendation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended food: fruits and panner,sugar free foods\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Ensure you download stopwords and punkt before use\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(r\"C:\\Users\\VIKRAM\\Downloads\\NLP DATASET.xlsx\")\n",
    "\n",
    "# Step 1: Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers and special characters\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Join the cleaned words back into a single string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Step 2: Apply preprocessing to each of the columns that we'll use\n",
    "df['type'] = df['type'].apply(preprocess_text)\n",
    "df['meal type'] = df['meal type'].apply(preprocess_text)\n",
    "df['person type'] = df['person type'].apply(preprocess_text)\n",
    "df['diet type'] = df['diet type'].apply(preprocess_text)\n",
    "\n",
    "# Combine the relevant columns to create a feature set for the recommendation system\n",
    "df['features'] = df['type'] + \" \" + df['meal type'] + \" \" + df['person type'] + \" \" + df['diet type']\n",
    "\n",
    "# Step 3: Initialize TF-IDF Vectorizer for feature extraction\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data into TF-IDF vectors\n",
    "tfidf_matrix = vectorizer.fit_transform(df['features'])\n",
    "\n",
    "# Step 4: Define the recommendation function\n",
    "def recommend_food_nlp(meal_type, food_type, person_type, diet_type):\n",
    "    # Preprocess the user input\n",
    "    food_type = preprocess_text(food_type)\n",
    "    meal_type = preprocess_text(meal_type)\n",
    "    person_type = preprocess_text(person_type)\n",
    "    diet_type = preprocess_text(diet_type)\n",
    "    \n",
    "    # Combine the inputs into a query\n",
    "    user_input = f\"{food_type} {meal_type} {person_type} {diet_type}\"\n",
    "    \n",
    "    # Transform the user input into the TF-IDF vector\n",
    "    user_tfidf = vectorizer.transform([user_input])\n",
    "    \n",
    "    # Calculate the cosine similarity between user input and dataset\n",
    "    similarities = cosine_similarity(user_tfidf, tfidf_matrix)\n",
    "    \n",
    "    # Get the index of the highest similarity score\n",
    "    idx = similarities.argsort()[0][-1]\n",
    "    \n",
    "    # Return the recommended food\n",
    "    return df['recommend'].iloc[idx]\n",
    "\n",
    "# Step 5: Collect input from the user\n",
    "meal_type = input(\"Enter meal type (e.g., breakfast, lunch, dinner): \").strip()\n",
    "food_type = input(\"Enter food type (e.g., veg, non-veg): \").strip()\n",
    "person_type = input(\"Enter person type (e.g., athletic, normal, weight loss): \").strip()\n",
    "diet_type = input(\"Enter diet type (e.g., high protein, low carb): \").strip()\n",
    "\n",
    "# Step 6: Get the recommendation based on user input\n",
    "recommendation = recommend_food_nlp(meal_type, food_type, person_type, diet_type)\n",
    "print(\"Recommended food:\", recommendation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import gradio as gr\n",
    "\n",
    "# Ensure you download stopwords and punkt before use\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(r\"C:\\Users\\VIKRAM\\Downloads\\NLP DATASET.xlsx\")\n",
    "\n",
    "# Step 1: Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers and special characters\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Join the cleaned words back into a single string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Step 2: Apply preprocessing to each of the columns that we'll use\n",
    "df['type'] = df['type'].apply(preprocess_text)\n",
    "df['meal type'] = df['meal type'].apply(preprocess_text)\n",
    "df['person type'] = df['person type'].apply(preprocess_text)\n",
    "df['diet type'] = df['diet type'].apply(preprocess_text)\n",
    "\n",
    "# Combine the relevant columns to create a feature set for the recommendation system\n",
    "df['features'] = df['type'] + \" \" + df['meal type'] + \" \" + df['person type'] + \" \" + df['diet type']\n",
    "\n",
    "# Step 3: Initialize TF-IDF Vectorizer for feature extraction\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data into TF-IDF vectors\n",
    "tfidf_matrix = vectorizer.fit_transform(df['features'])\n",
    "\n",
    "# Step 4: Define the recommendation function\n",
    "def recommend_food_nlp(meal_type, food_type, person_type, diet_type):\n",
    "    # Preprocess the user input\n",
    "    food_type = preprocess_text(food_type)\n",
    "    meal_type = preprocess_text(meal_type)\n",
    "    person_type = preprocess_text(person_type)\n",
    "    diet_type = preprocess_text(diet_type)\n",
    "    \n",
    "    # Combine the inputs into a query\n",
    "    user_input = f\"{food_type} {meal_type} {person_type} {diet_type}\"\n",
    "    \n",
    "    # Transform the user input into the TF-IDF vector\n",
    "    user_tfidf = vectorizer.transform([user_input])\n",
    "    \n",
    "    # Calculate the cosine similarity between user input and dataset\n",
    "    similarities = cosine_similarity(user_tfidf, tfidf_matrix)\n",
    "    \n",
    "    # Get the index of the highest similarity score\n",
    "    idx = similarities.argsort()[0][-1]\n",
    "    \n",
    "    # Return the recommended food\n",
    "    return df['recommend'].iloc[idx]\n",
    "\n",
    "# Step 5: Create a Gradio interface\n",
    "def recommend(meal_type, food_type, person_type, diet_type):\n",
    "    recommendation = recommend_food_nlp(meal_type, food_type, person_type, diet_type)\n",
    "    return f\"Recommended food: {recommendation}\"\n",
    "\n",
    "# Step 6: Define the Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=recommend,  # Function to run\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Meal Type (e.g., breakfast, lunch, dinner)\"),\n",
    "        gr.Textbox(label=\"Food Type (e.g., veg, non-veg)\"),\n",
    "        gr.Textbox(label=\"Person Type (e.g., athletic, normal, weight loss)\"),\n",
    "        gr.Textbox(label=\"Diet Type (e.g., high protein, low carb)\")\n",
    "    ],\n",
    "    outputs=\"text\",  # Output type\n",
    "    title=\"Food Recommendation System\",\n",
    "    description=\"Enter your preferences to get a food recommendation based on your meal type, food type, person type, and diet type.\",\n",
    ")\n",
    "\n",
    "# Step 7: Launch the Gradio app\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended food: Broccoli and chickpea salad; whole grain bread.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Ensure you download stopwords and punkt before use\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Load both datasets\n",
    "df_normal = pd.read_excel(r\"C:\\Users\\VIKRAM\\Downloads\\NLP DATASET.xlsx\")\n",
    "df_diseased = pd.read_excel(r\"C:\\Users\\VIKRAM\\Downloads\\nlp dieseases dataset.xlsx\")\n",
    "\n",
    "# Step 1: Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers and special characters\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Join the cleaned words back into a single string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Step 2: Apply preprocessing to each of the columns that we'll use\n",
    "# Normal diet columns: type, meal type, person type, diet type\n",
    "df_normal['type'] = df_normal['type'].apply(preprocess_text)\n",
    "df_normal['meal type'] = df_normal['meal type'].apply(preprocess_text)\n",
    "df_normal['person type'] = df_normal['person type'].apply(preprocess_text)\n",
    "df_normal['diet type'] = df_normal['diet type'].apply(preprocess_text)\n",
    "\n",
    "# Diseased diet columns: type, meal type, disease type\n",
    "df_diseased['type'] = df_diseased['type'].apply(preprocess_text)\n",
    "df_diseased['meal type'] = df_diseased['meal type'].apply(preprocess_text)\n",
    "df_diseased['disease type'] = df_diseased['disease type'].apply(preprocess_text)\n",
    "\n",
    "# Create a feature set for each dataset\n",
    "df_normal['features'] = df_normal['type'] + \" \" + df_normal['meal type'] + \" \" + df_normal['person type'] + \" \" + df_normal['diet type']\n",
    "df_diseased['features'] = df_diseased['type'] + \" \" + df_diseased['meal type'] + \" \" + df_diseased['disease type']\n",
    "\n",
    "# Step 3: Initialize TF-IDF Vectorizers and transform datasets\n",
    "vectorizer_normal = TfidfVectorizer()\n",
    "vectorizer_diseased = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix_normal = vectorizer_normal.fit_transform(df_normal['features'])\n",
    "tfidf_matrix_diseased = vectorizer_diseased.fit_transform(df_diseased['features'])\n",
    "\n",
    "# Step 4: Define the recommendation function\n",
    "def recommend_food_nlp(diet_preference, **kwargs):\n",
    "    if diet_preference == \"normal\":\n",
    "        # Combine the user inputs for normal diet\n",
    "        food_type = preprocess_text(kwargs.get('food_type'))\n",
    "        meal_type = preprocess_text(kwargs.get('meal_type'))\n",
    "        person_type = preprocess_text(kwargs.get('person_type'))\n",
    "        diet_type = preprocess_text(kwargs.get('diet_type'))\n",
    "        user_input = f\"{food_type} {meal_type} {person_type} {diet_type}\"\n",
    "        \n",
    "        # Transform the user input into the TF-IDF vector for the normal dataset\n",
    "        user_tfidf = vectorizer_normal.transform([user_input])\n",
    "        \n",
    "        # Calculate cosine similarity between user input and the normal dataset\n",
    "        similarities = cosine_similarity(user_tfidf, tfidf_matrix_normal)\n",
    "        idx = similarities.argsort()[0][-1]\n",
    "        \n",
    "        # Return the recommended food from the normal dataset\n",
    "        return df_normal['recommend'].iloc[idx]\n",
    "    \n",
    "    elif diet_preference == \"diseased\":\n",
    "        # Combine the user inputs for diseased diet\n",
    "        type_ = preprocess_text(kwargs.get('type'))\n",
    "        meal_type = preprocess_text(kwargs.get('meal_type'))\n",
    "        disease_type = preprocess_text(kwargs.get('disease_type'))\n",
    "        user_input = f\"{type_} {meal_type} {disease_type}\"\n",
    "        \n",
    "        # Transform the user input into the TF-IDF vector for the diseased dataset\n",
    "        user_tfidf = vectorizer_diseased.transform([user_input])\n",
    "        \n",
    "        # Calculate cosine similarity between user input and the diseased dataset\n",
    "        similarities = cosine_similarity(user_tfidf, tfidf_matrix_diseased)\n",
    "        idx = similarities.argsort()[0][-1]\n",
    "        \n",
    "        # Return the recommended food from the diseased dataset\n",
    "        return df_diseased['recommend'].iloc[idx]\n",
    "    \n",
    "    else:\n",
    "        return \"Invalid diet preference. Choose 'normal' or 'diseased'.\"\n",
    "\n",
    "# Step 5: Get user inputs and proceed with the appropriate recommendation\n",
    "diet_preference = input(\"Would you like a 'normal' or 'diseased' diet recommendation? \").strip().lower()\n",
    "\n",
    "if diet_preference == \"normal\":\n",
    "    meal_type = input(\"Enter the meal type (e.g., breakfast, lunch, dinner): \").strip().lower()\n",
    "    food_type = input(\"Enter the food type (e.g., veg, non-veg): \").strip().lower()\n",
    "    person_type = input(\"Enter the person type (e.g., athletic, elderly, etc.): \").strip().lower()\n",
    "    diet_type = input(\"Enter the diet type (e.g., high protein, low carb, etc.): \").strip().lower()\n",
    "    \n",
    "    # Get the recommendation for a normal diet\n",
    "    recommendation = recommend_food_nlp(diet_preference, meal_type=meal_type, food_type=food_type, person_type=person_type, diet_type=diet_type)\n",
    "    print(\"Recommended food:\", recommendation)\n",
    "\n",
    "elif diet_preference == \"diseased\":\n",
    "    type_ = input(\"Enter the food type (e.g., veg, non-veg): \").strip().lower()\n",
    "    meal_type = input(\"Enter the meal type (e.g., breakfast, lunch, dinner): \").strip().lower()\n",
    "    disease_type = input(\"Enter the disease type (e.g., diabetes, hypertension): \").strip().lower()\n",
    "    \n",
    "    # Get the recommendation for a diseased diet\n",
    "    recommendation = recommend_food_nlp(diet_preference, type=type_, meal_type=meal_type, disease_type=disease_type)\n",
    "    print(\"Recommended food:\", recommendation)\n",
    "    \n",
    "else:\n",
    "    print(\"Invalid input. Please restart and enter 'normal' or 'diseased' for diet preference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Ensure you download stopwords and punkt before use\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Load datasets\n",
    "df_normal = pd.read_excel(r\"C:\\Users\\VIKRAM\\Downloads\\NLP DATASET.xlsx\")\n",
    "df_diseased = pd.read_excel(r\"C:\\Users\\VIKRAM\\Downloads\\nlp dieseases dataset.xlsx\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Preprocess datasets\n",
    "df_normal['type'] = df_normal['type'].apply(preprocess_text)\n",
    "df_normal['meal type'] = df_normal['meal type'].apply(preprocess_text)\n",
    "df_normal['person type'] = df_normal['person type'].apply(preprocess_text)\n",
    "df_normal['diet type'] = df_normal['diet type'].apply(preprocess_text)\n",
    "\n",
    "df_diseased['type'] = df_diseased['type'].apply(preprocess_text)\n",
    "df_diseased['meal type'] = df_diseased['meal type'].apply(preprocess_text)\n",
    "df_diseased['disease type'] = df_diseased['disease type'].apply(preprocess_text)\n",
    "\n",
    "df_normal['features'] = df_normal['type'] + \" \" + df_normal['meal type'] + \" \" + df_normal['person type'] + \" \" + df_normal['diet type']\n",
    "df_diseased['features'] = df_diseased['type'] + \" \" + df_diseased['meal type'] + \" \" + df_diseased['disease type']\n",
    "\n",
    "# Vectorize features\n",
    "vectorizer_normal = TfidfVectorizer()\n",
    "vectorizer_diseased = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix_normal = vectorizer_normal.fit_transform(df_normal['features'])\n",
    "tfidf_matrix_diseased = vectorizer_diseased.fit_transform(df_diseased['features'])\n",
    "\n",
    "# Recommendation function\n",
    "def recommend_food_nlp(diet_preference, **kwargs):\n",
    "    if diet_preference == \"normal\":\n",
    "        food_type = preprocess_text(kwargs.get('food_type'))\n",
    "        meal_type = preprocess_text(kwargs.get('meal_type'))\n",
    "        person_type = preprocess_text(kwargs.get('person_type'))\n",
    "        diet_type = preprocess_text(kwargs.get('diet_type'))\n",
    "        user_input = f\"{food_type} {meal_type} {person_type} {diet_type}\"\n",
    "        user_tfidf = vectorizer_normal.transform([user_input])\n",
    "        similarities = cosine_similarity(user_tfidf, tfidf_matrix_normal)\n",
    "        idx = similarities.argsort()[0][-1]\n",
    "        return df_normal['recommend'].iloc[idx]\n",
    "    \n",
    "    elif diet_preference == \"diseased\":\n",
    "        type_ = preprocess_text(kwargs.get('type'))\n",
    "        meal_type = preprocess_text(kwargs.get('meal_type'))\n",
    "        disease_type = preprocess_text(kwargs.get('disease_type'))\n",
    "        user_input = f\"{type_} {meal_type} {disease_type}\"\n",
    "        user_tfidf = vectorizer_diseased.transform([user_input])\n",
    "        similarities = cosine_similarity(user_tfidf, tfidf_matrix_diseased)\n",
    "        idx = similarities.argsort()[0][-1]\n",
    "        return df_diseased['recommend'].iloc[idx]\n",
    "\n",
    "# GUI Code using Tkinter\n",
    "class FoodRecommendationApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Food Recommendation System\")\n",
    "        self.root.geometry(\"400x400\")\n",
    "\n",
    "        self.diet_pref_label = tk.Label(root, text=\"Select Diet Preference:\")\n",
    "        self.diet_pref_label.pack()\n",
    "\n",
    "        self.diet_pref = tk.StringVar()\n",
    "        self.normal_radio = tk.Radiobutton(root, text=\"Normal\", variable=self.diet_pref, value=\"normal\", command=self.show_normal_form)\n",
    "        self.normal_radio.pack()\n",
    "        self.diseased_radio = tk.Radiobutton(root, text=\"Diseased\", variable=self.diet_pref, value=\"diseased\", command=self.show_diseased_form)\n",
    "        self.diseased_radio.pack()\n",
    "\n",
    "        self.normal_frame = None\n",
    "        self.diseased_frame = None\n",
    "\n",
    "    def show_normal_form(self):\n",
    "        self.clear_frames()\n",
    "        self.normal_frame = tk.Frame(self.root)\n",
    "        self.normal_frame.pack()\n",
    "\n",
    "        self.meal_type_label = tk.Label(self.normal_frame, text=\"Meal Type:\")\n",
    "        self.meal_type_label.pack()\n",
    "        self.meal_type_entry = tk.Entry(self.normal_frame)\n",
    "        self.meal_type_entry.pack()\n",
    "\n",
    "        self.food_type_label = tk.Label(self.normal_frame, text=\"Food Type:\")\n",
    "        self.food_type_label.pack()\n",
    "        self.food_type_entry = tk.Entry(self.normal_frame)\n",
    "        self.food_type_entry.pack()\n",
    "\n",
    "        self.person_type_label = tk.Label(self.normal_frame, text=\"Person Type:\")\n",
    "        self.person_type_label.pack()\n",
    "        self.person_type_entry = tk.Entry(self.normal_frame)\n",
    "        self.person_type_entry.pack()\n",
    "\n",
    "        self.diet_type_label = tk.Label(self.normal_frame, text=\"Diet Type:\")\n",
    "        self.diet_type_label.pack()\n",
    "        self.diet_type_entry = tk.Entry(self.normal_frame)\n",
    "        self.diet_type_entry.pack()\n",
    "\n",
    "        self.submit_btn = tk.Button(self.normal_frame, text=\"Get Recommendation\", command=self.get_normal_recommendation)\n",
    "        self.submit_btn.pack()\n",
    "\n",
    "    def show_diseased_form(self):\n",
    "        self.clear_frames()\n",
    "        self.diseased_frame = tk.Frame(self.root)\n",
    "        self.diseased_frame.pack()\n",
    "\n",
    "        self.type_label = tk.Label(self.diseased_frame, text=\"Food Type:\")\n",
    "        self.type_label.pack()\n",
    "        self.type_entry = tk.Entry(self.diseased_frame)\n",
    "        self.type_entry.pack()\n",
    "\n",
    "        self.meal_type_label = tk.Label(self.diseased_frame, text=\"Meal Type:\")\n",
    "        self.meal_type_label.pack()\n",
    "        self.meal_type_entry = tk.Entry(self.diseased_frame)\n",
    "        self.meal_type_entry.pack()\n",
    "\n",
    "        self.disease_type_label = tk.Label(self.diseased_frame, text=\"Disease Type:\")\n",
    "        self.disease_type_label.pack()\n",
    "        self.disease_type_entry = tk.Entry(self.diseased_frame)\n",
    "        self.disease_type_entry.pack()\n",
    "\n",
    "        self.submit_btn = tk.Button(self.diseased_frame, text=\"Get Recommendation\", command=self.get_diseased_recommendation)\n",
    "        self.submit_btn.pack()\n",
    "\n",
    "    def clear_frames(self):\n",
    "        if self.normal_frame:\n",
    "            self.normal_frame.destroy()\n",
    "        if self.diseased_frame:\n",
    "            self.diseased_frame.destroy()\n",
    "\n",
    "    def get_normal_recommendation(self):\n",
    "        meal_type = self.meal_type_entry.get()\n",
    "        food_type = self.food_type_entry.get()\n",
    "        person_type = self.person_type_entry.get()\n",
    "        diet_type = self.diet_type_entry.get()\n",
    "\n",
    "        recommendation = recommend_food_nlp(\"normal\", meal_type=meal_type, food_type=food_type, person_type=person_type, diet_type=diet_type)\n",
    "        messagebox.showinfo(\"Recommendation\", f\"Recommended food: {recommendation}\")\n",
    "\n",
    "    def get_diseased_recommendation(self):\n",
    "        type_ = self.type_entry.get()\n",
    "        meal_type = self.meal_type_entry.get()\n",
    "        disease_type = self.disease_type_entry.get()\n",
    "\n",
    "        recommendation = recommend_food_nlp(\"diseased\", type=type_, meal_type=meal_type, disease_type=disease_type)\n",
    "        messagebox.showinfo(\"Recommendation\", f\"Recommended food: {recommendation}\")\n",
    "\n",
    "# Start the GUI\n",
    "root = tk.Tk()\n",
    "app = FoodRecommendationApp(root)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
